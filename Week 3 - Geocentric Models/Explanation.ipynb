{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocentric Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocentric Metaphor: \n",
    "Linear regression is compared to a geocentric model. Just like a geocentric model simplifies the complex reality of the universe by placing the earth at the center, linear regression simplifies the complex relationships between variables by assuming a linear relationship. Despite this simplification, both models are useful for making predictions and describing relationships.\n",
    "\n",
    "\n",
    "### Gaussian Error Model: \n",
    "Linear regression assumes that the errors, or the differences between the observed and predicted values, are normally distributed. This is a generalization that helps in the mathematical formulation and computation of the model. It does not provide a detailed explanation of all possible sources of errors or their distributions.\n",
    "\n",
    "### Causal vs. Statistical Models: \n",
    "In using linear regression, it’s important to distinguish between the statistical model and the actual causal mechanisms in the real world. The statistical model, which is linear regression in this case, is used for making predictions. However, the actual causal mechanisms that operate in the real world might be more complex. Mistaking the statistical model for the actual causal mechanisms can lead to incorrect conclusions.\n",
    "\n",
    "### Special Cases: \n",
    "Linear regression forms the basis for other statistical procedures like ANOVA (Analysis of Variance), ANCOVA (Analysis of Covariance), and t-tests. These procedures are variations of the same fundamental model, i.e., they all assume a linear relationship between variables. However, they differ in the way they summarize and interpret the results. For example, ANOVA is used to compare the means of different groups, while t-tests are used to compare the means of two groups.\n",
    "\n",
    "<img src=\"images/image1.png\" width=\"600\" height=\"400\" /> \n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Distributions\n",
    "\n",
    "### Origin of Gaussian Distributions\n",
    "\n",
    "Gaussian distributions often arise from the addition of many small, independent fluctuations. This is demonstrated by a thought experiment where individuals flip a coin and take steps to the left or right based on the outcome. Over time, the distribution of individuals' positions tends to form a Gaussian distribution.\n",
    "\n",
    "<img src=\"images/image2.png\" width=\"600\" height=\"400\" /> \n",
    "\n",
    "### Two Arguments for Gaussian Distributions\n",
    "\n",
    "> `Generative Argument`\n",
    ">> Many natural processes involve the addition of small fluctuations. For example, growth in living organisms involves yearly fluctuations in height or body mass. When we look at the size of animals in a population of the same age, they tend to have a Gaussian distribution.\n",
    "\n",
    "> `Inferential Argument`\n",
    ">> If our goal is to estimate the mean and variance of some variable, the Gaussian distribution is the best one to use. It is the least informative distribution, meaning it contains no other information than a mean and a variance. This makes it the most spread out distribution, covering the greatest number of possibilities.\n",
    "\n",
    "### Usefulness of Gaussian Distributions\n",
    "\n",
    "A variable does not have to be empirically normally distributed for the Gaussian error model to be useful statistically. It's a tool for estimating the mean and variance and is effective even if the actual distribution differs from the Gaussian distribution.\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "<img src=\"images/image4.png\" width=\"600\" height=\"400\" /> <img src=\"images/workflow_lr.png\" width=\"600\" height=\"400\" /> \n",
    "\n",
    "<img src=\"images/image5.png\" width=\"600\" height=\"400\" /> <img src=\"images/image6.png\" width=\"600\" height=\"400\" /> \n",
    "\n",
    "<img src=\"images/image7.png\" width=\"400\" height=\"250\" /> <img src=\"images/image8.png\" width=\"400\" height=\"250\" /> <img src=\"images/image9.png\" width=\"400\" height=\"250\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image11.png\" width=\"600\" height=\"400\" /> \n",
    "\n",
    "<img src=\"images/image12.png\" width=\"300\" height=\"200\" />  <img src=\"images/image13_1.png\" width=\"300\" height=\"200\" />  <img src=\"images/image13.png\" width=\"300\" height=\"200\"  /> \n",
    "\n",
    "### Equation or Deterministic\n",
    "<img src=\"images/image14.png\" width=\"400\" height=\"250\" />\n",
    "\n",
    "### Distribution\n",
    "<img src=\"images/image15.png\" width=\"400\" height=\"250\" />\n",
    "\n",
    "### Distribution\n",
    "<img src=\"images/image16.png\" width=\"400\" height=\"250\" />\n",
    "\n",
    "### Order\n",
    "<img src=\"images/image17.png\" width=\"400\" height=\"250\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Estimator\n",
    "\n",
    "<img src=\"images/image19.png\" width=\"600\" height=\"400\" /> <img src=\"images/image20.png\" width=\"600\" height=\"400\" />\n",
    "\n",
    "<img src=\"images/image21.png\" width=\"600\" height=\"400\" /> <img src=\"images/image22.png\" width=\"600\" height=\"400\" />\n",
    "\n",
    "\n",
    "<img src=\"images/image23.png\" width=\"600\" height=\"400\" />\n",
    "\n",
    "#### As we add more observations the **posterior probability** masses up on fewer lines.\n",
    "<img src=\"images/image24.png\" width=\"800\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4tzzVdRDl7I\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image25.png\" width=\"600\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "## Quadratic Approximation and Prior Predictive Distribution\n",
    "\n",
    "### Quadratic Approximation\n",
    "Quadratic approximation is a method used to approximate the posterior distribution as a multivariate Gaussian distribution. This is done because posterior distributions often resemble multivariate Gaussian distributions, especially when the sample size is reasonably large.\n",
    "\n",
    "The term \"quadratic\" comes from the fact that a Gaussian distribution is quadratic in nature. In the logarithmic space, the Gaussian distribution forms a perfect parabola, hence the name.\n",
    "\n",
    "The tool used for this process is called QWAP (Quadratic Approximation), which is part of the rethinking package. QWAP allows you to input a list of deterministic and distributional assumptions that define a statistical model. It then runs the model and finds the Gaussian approximation of the posterior distribution for the model and the data you pass it.\n",
    "\n",
    "### Prior Predictive Distribution\n",
    "Prior predictive distribution is a concept in Bayesian statistics where you make predictions based on the prior, even before the model has seen any data. The goal here is to set priors that prevent the model from making unrealistic predictions.\n",
    "\n",
    "<img src=\"images/image26.png\" width=\"500\" height=\"300\" />\n",
    "\n",
    "In the context of a model relating height and weight:\n",
    "- **Intercept (α)**: This is expected to be close to zero, as someone with zero height should also have zero weight. A normal distribution centered around zero is used for α, allowing the model to adjust if the relationship doesn't hold.\n",
    "- **Slope (β)**: This should be positive but less than 1, reflecting that weight generally increases with height but not as fast as height increases. A uniform distribution between zero and one is used for β.\n",
    "- **Standard Deviation (σ)**: This represents variability in weight. Since standard deviations cannot be negative, σ must be positive. A uniform distribution between zero and ten is used for σ.\n",
    "\n",
    "These priors are set based on scientific knowledge but are flexible enough to allow the model to learn from the data. The aim is not to predict exact weights but to ensure that the predictions stay within realistic bounds before any data is analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image27.png\" width=\"600\" height=\"300\" /> <img src=\"images/image28.png\" width=\"600\" height=\"300\" />\n",
    "\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image29.png\" width=\"600\" height=\"400\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image30.png\" width=\"600\" height=\"300\" /> <img src=\"images/image32.png\" width=\"600\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/law.png\" width=\"600\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Linear Regression Recap\n",
    "\n",
    "In Bayesian linear regression, the goal is to estimate the relationship between the predictor (height) and the response (weight) while accounting for uncertainty. This is done by defining prior distributions for the model parameters (intercept, slope, and noise), and then updating these priors with data to obtain the posterior distribution.\n",
    "\n",
    "### Posterior Distribution\n",
    "\n",
    "The posterior distribution of the model parameters is the result of combining the prior beliefs with the likelihood of the observed data. This distribution reflects our updated beliefs about the parameters after considering the data.\n",
    "\n",
    "### Sampling from the Posterior\n",
    "\n",
    "Using methods like Markov Chain Monte Carlo (MCMC), we draw samples from the posterior distribution. Each sample represents a possible set of parameter values that could explain the data. For a simple linear regression model, these parameters typically include:\n",
    "\n",
    "- Intercept (`a`)\n",
    "- Slope (`b`)\n",
    "\n",
    "### Plotting Posterior Predictive Lines\n",
    "\n",
    "When we plot the regression lines sampled from the posterior, we are visualizing the uncertainty in our model. Each line represents a possible linear relationship between the predictor and the response, based on the sampled parameters. Here’s what the lines represent:\n",
    "\n",
    "1. **Multiple Possible Regression Lines**: Each line corresponds to one set of intercept (`a`) and slope (`b`) values sampled from the posterior distribution. This shows the range of possible linear relationships that are consistent with the data and the prior information.\n",
    "2. **Visualizing Uncertainty**: The spread of the lines illustrates the uncertainty in the model’s predictions. If the lines are close together, it indicates higher certainty in the predicted relationship. A wider spread indicates greater uncertainty.\n",
    "3. **Posterior Predictive Distribution**: The lines are part of the posterior predictive distribution, which represents the distribution of possible future observations given the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/all_plots.png\" width=\"600\" height=\"300\" /> <img src=\"images/percentile.png\" width=\"600\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
